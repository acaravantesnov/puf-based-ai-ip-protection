{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec4f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "from src import mnist\n",
    "from src import config\n",
    "from src import analysis as an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lock_keras_model(model, key):\n",
    "    # Get current weights and biases from the Keras model\n",
    "    # get_weights() returns a flat list: [W1, b1, W2, b2, W3, b3, W4, b4]\n",
    "    keras_weights_and_biases = model.get_weights()\n",
    "\n",
    "    # Extract only the weight matrices (kernel) from the list\n",
    "    weight_matrices = [keras_weights_and_biases[i] for i in range(0, len(keras_weights_and_biases), 2)]\n",
    "    bias_vectors = [keras_weights_and_biases[i] for i in range(1, len(keras_weights_and_biases), 2)]\n",
    "\n",
    "    permutation_matrices = []\n",
    "    \n",
    "    # Generate permutation matrices based on the shapes of the weight matrices\n",
    "    for i in range(4): # For W1, W2, W3, W4\n",
    "        W = weight_matrices[i]\n",
    "        \n",
    "        # P_row (permutation for rows of W)\n",
    "        P_row = np.eye(W.shape[0])\n",
    "        np.random.seed(key[2 * i])\n",
    "        np.random.shuffle(P_row)\n",
    "        permutation_matrices.append(P_row)\n",
    "\n",
    "        # P_col (permutation for columns of W)\n",
    "        P_col = np.eye(W.shape[1])\n",
    "        np.random.seed(key[2 * i + 1])\n",
    "        np.random.shuffle(P_col)\n",
    "        permutation_matrices.append(P_col)\n",
    "\n",
    "    # Apply permutations to weights: W_new = P_row  W_old  P_col\n",
    "    new_weight_matrices = []\n",
    "    for i in range(4):\n",
    "        W_old = weight_matrices[i]\n",
    "        P_row = permutation_matrices[2 * i]\n",
    "        P_col = permutation_matrices[2 * i + 1]\n",
    "        \n",
    "        # Perform matrix multiplications\n",
    "        permuted_W = np.dot(P_row, W_old)\n",
    "        permuted_W = np.dot(permuted_W, P_col)\n",
    "        new_weight_matrices.append(permuted_W)\n",
    "\n",
    "    # Reconstruct the list of weights and biases to set back into the model\n",
    "    # The order must be [new_W1, b1, new_W2, b2, new_W3, b3, new_W4, b4]\n",
    "    updated_keras_weights_and_biases = []\n",
    "    for i in range(4):\n",
    "        updated_keras_weights_and_biases.append(new_weight_matrices[i])\n",
    "        updated_keras_weights_and_biases.append(bias_vectors[i])\n",
    "\n",
    "    # Set the permuted weights back into the Keras model\n",
    "    model.set_weights(updated_keras_weights_and_biases)\n",
    "    print(\"\\nModel weights have been 'locked' (permuted).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset using custom MNIST class...\n",
      "MNIST Data loaded and processed:\n",
      "  x_train shape: (60000, 784), dtype: float32\n",
      "  y_train shape: (60000, 10), dtype: float64\n",
      "  x_test shape: (10000, 784), dtype: float32\n",
      "  y_test shape: (10000, 10), dtype: float64\n",
      "MNIST dataset loaded and preprocessed using custom class.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │        \u001b[38;5;34m28,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">439,234</span> (1.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m439,234\u001b[0m (1.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">439,234</span> (1.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m439,234\u001b[0m (1.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training on MNIST ---\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.5525 - val_accuracy: 0.9677 - val_loss: 0.1175\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1113 - val_accuracy: 0.9763 - val_loss: 0.0795\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0626 - val_accuracy: 0.9777 - val_loss: 0.0762\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0420 - val_accuracy: 0.9783 - val_loss: 0.0747\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0314 - val_accuracy: 0.9782 - val_loss: 0.0748\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0227 - val_accuracy: 0.9792 - val_loss: 0.0752\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0194 - val_accuracy: 0.9818 - val_loss: 0.0692\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0176 - val_accuracy: 0.9813 - val_loss: 0.0728\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0144 - val_accuracy: 0.9807 - val_loss: 0.0816\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 0.9828 - val_loss: 0.0763\n",
      "--- Model Training Complete ---\n",
      "\n",
      "--- Evaluating the Model on Test Set ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9788 - loss: 0.0930\n",
      "Test Loss: 0.0814\n",
      "Test Accuracy: 0.9812\n",
      "--- Model Evaluation Complete ---\n",
      "locking keys = [51900, 18752, 4179, 8369, 25064, 5127, 24, 51299]\n",
      "\n",
      "Model weights have been 'locked' (permuted).\n",
      "\n",
      "--- Exporting Weights and Biases to CSV files ---\n",
      "Saved weights for hidden_layer_1 to models\\mnist_mlp\\mnist_mlp_w1.npy (shape: (784, 512))\n",
      "Saved biases for hidden_layer_1 to models\\mnist_mlp\\mnist_mlp_b1.npy (shape: (512,))\n",
      "Saved weights for hidden_layer_2 to models\\mnist_mlp\\mnist_mlp_w2.npy (shape: (512, 56))\n",
      "Saved biases for hidden_layer_2 to models\\mnist_mlp\\mnist_mlp_b2.npy (shape: (56,))\n",
      "Saved weights for hidden_layer_3 to models\\mnist_mlp\\mnist_mlp_w3.npy (shape: (56, 128))\n",
      "Saved biases for hidden_layer_3 to models\\mnist_mlp\\mnist_mlp_b3.npy (shape: (128,))\n",
      "Saved weights for output_layer to models\\mnist_mlp\\mnist_mlp_w4.npy (shape: (128, 10))\n",
      "Saved biases for output_layer to models\\mnist_mlp\\mnist_mlp_b4.npy (shape: (10,))\n",
      "\n",
      "All weights and biases exported to the 'models\\mnist_mlp' directory.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MNIST dataset using custom MNIST class...\")\n",
    "\n",
    "try:\n",
    "    mnist_data_loader = mnist.MNIST(\n",
    "        config.TRAINING_IMAGES_FILEPATH, config.TRAINING_LABELS_FILEPATH,\n",
    "        config.TEST_IMAGES_FILEPATH, config.TEST_LABELS_FILEPATH\n",
    "    )\n",
    "    x_train, y_train = mnist_data_loader.x_train, mnist_data_loader.y_train\n",
    "    x_test, y_test = mnist_data_loader.x_test, mnist_data_loader.y_test\n",
    "    print(\"MNIST dataset loaded and preprocessed using custom class.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading MNIST files: {e}. Please ensure the MNIST dataset files are in the correct directory.\")\n",
    "    print(\"Expected paths:\")\n",
    "    print(f\"  Training Images: {config.TRAINING_IMAGES_FILEPATH}\")\n",
    "    print(f\"  Training Labels: {config.TRAINING_LABELS_FILEPATH}\")\n",
    "    print(f\"  Test Images: {config.TEST_IMAGES_FILEPATH}\")\n",
    "    print(f\"  Test Labels: {config.TEST_LABELS_FILEPATH}\")\n",
    "    exit()\n",
    "\n",
    "num_classes = 10\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,)), # Input shape is 28*28 = 784\n",
    "        layers.Dense(512, activation=\"relu\", name=\"hidden_layer_1\"),\n",
    "        layers.Dense(56, activation=\"relu\", name=\"hidden_layer_2\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"hidden_layer_3\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n--- Starting Model Training on MNIST ---\")\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)\n",
    "print(\"--- Model Training Complete ---\")\n",
    "\n",
    "print(\"\\n--- Evaluating the Model on Test Set ---\")\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"--- Model Evaluation Complete ---\")\n",
    "\n",
    "raw_data_df = pd.read_csv(r'data\\raw\\v2\\pynq_1_data.csv', dtype=str)\n",
    "lock_key = an.convert_binary_to_naturals(an.get_ideal_value(raw_data_df, 'PUF_Response_Value'), chunk_size=16)\n",
    "print(f'locking keys = {lock_key}')\n",
    "lock_keras_model(model, lock_key)\n",
    "\n",
    "print(\"\\n--- Exporting Weights and Biases to CSV files ---\")\n",
    "\n",
    "# Create a directory to store the CSV files if it doesnt exist\n",
    "output_dir = r'models\\mnist_mlp'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, layers.Dense):\n",
    "        weights, biases = layer.get_weights()\n",
    "\n",
    "        # Save weights to a .npy file (lossless binary format)\n",
    "        weight_filename = os.path.join(output_dir, f\"mnist_mlp_w{i+1}.npy\")\n",
    "        np.save(weight_filename, weights)\n",
    "        print(f\"Saved weights for {layer.name} to {weight_filename} (shape: {weights.shape})\")\n",
    "\n",
    "        # Save biases to a .npy file\n",
    "        bias_filename = os.path.join(output_dir, f\"mnist_mlp_b{i+1}.npy\")\n",
    "        np.save(bias_filename, biases)\n",
    "        print(f\"Saved biases for {layer.name} to {bias_filename} (shape: {biases.shape})\")\n",
    "\n",
    "print(f\"\\nAll weights and biases exported to the '{output_dir}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ring_oscillator_puf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
