{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21541bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# print(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import mlp\n",
    "from src import mnist\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29921888",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6203352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Data loaded and processed:\n",
      "  x_train shape: (60000, 784), dtype: float32\n",
      "  y_train shape: (60000, 10), dtype: float64\n",
      "  x_test shape: (10000, 784), dtype: float32\n",
      "  y_test shape: (10000, 10), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mlp = mlp.MLP(num_classes = config.NUM_CLASSES, learning_rate = config.LEARNING_RATE)\n",
    "mnist = mnist.MNIST(config.TRAINING_IMAGES_FILEPATH,\n",
    "              config.TRAINING_LABELS_FILEPATH,\n",
    "              config.TEST_IMAGES_FILEPATH,\n",
    "              config.TEST_LABELS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93045bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: (784, 512), W2: (512, 56), W3: (56, 128), W4: (128, 10)\n",
      "b1: (1, 512), b2: (1, 56), b3: (1, 128), b4: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and initialize weights and biases\n",
    "np.random.seed(42)\n",
    "mlp.initialize_weights(config.INPUT_SIZE, config.HIDDEN_SIZES)\n",
    "\n",
    "print(f\"W1: {mlp.weights['W1'].shape}, W2: {mlp.weights['W2'].shape}, W3: {mlp.weights['W3'].shape}, W4: {mlp.weights['W4'].shape}\")\n",
    "print(f\"b1: {mlp.biases['b1'].shape}, b2: {mlp.biases['b2'].shape}, b3: {mlp.biases['b3'].shape}, b4: {mlp.biases['b4'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d34ea",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a785de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training accuracy: 11.24%\n",
      "Epoch 2, training accuracy: 11.24%\n",
      "Epoch 3, training accuracy: 11.24%\n",
      "Epoch 4, training accuracy: 11.24%\n",
      "Epoch 5, training accuracy: 11.24%\n",
      "Epoch 6, training accuracy: 11.24%\n",
      "Epoch 7, training accuracy: 21.11%\n",
      "Epoch 8, training accuracy: 47.50%\n",
      "Epoch 9, training accuracy: 73.66%\n",
      "Epoch 10, training accuracy: 86.53%\n",
      "Epoch 11, training accuracy: 90.39%\n",
      "Epoch 12, training accuracy: 92.46%\n",
      "Epoch 13, training accuracy: 94.16%\n",
      "Epoch 14, training accuracy: 95.08%\n",
      "Epoch 15, training accuracy: 96.07%\n",
      "Epoch 16, training accuracy: 96.52%\n",
      "Epoch 17, training accuracy: 96.77%\n",
      "Epoch 18, training accuracy: 97.33%\n",
      "Epoch 19, training accuracy: 97.50%\n",
      "Epoch 20, training accuracy: 98.11%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle training data at the start of each epoch\n",
    "    permutation = np.random.permutation(mnist.x_train.shape[0])\n",
    "    mnist.x_train = mnist.x_train[permutation]\n",
    "    mnist.y_train = mnist.y_train[permutation]\n",
    "\n",
    "    # Iterate over mini-batches\n",
    "    for i in range(0, mnist.x_train.shape[0], batch_size):\n",
    "        x_batch = mnist.x_train[i:i+batch_size]  # Extract batch inputs\n",
    "        y_batch = mnist.y_train[i:i+batch_size]  # Extract batch labels\n",
    "\n",
    "        # Perform forward and backward pass\n",
    "        activations = mlp.forward_pass(x_batch)\n",
    "        mlp.backward_pass(x_batch, y_batch, activations)\n",
    "\n",
    "    # Perform forward pass on training data\n",
    "    activations = mlp.forward_pass(mnist.x_train)\n",
    "\n",
    "    # Extract predictions from the output layer (softmax results)\n",
    "    train_pred = activations[f\"A{len(mlp.weights)}\"] \n",
    "\n",
    "    # Calculate accuracy\n",
    "    train_accuracy = np.mean(np.argmax(train_pred, axis=1) == np.argmax(mnist.y_train, axis=1))\n",
    "    print(f\"Epoch {epoch + 1}, training accuracy: {train_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416fdfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.66\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_activations = mlp.forward_pass(mnist.x_test)\n",
    "test_pred = test_activations[f\"A{len(mlp.weights)}\"]\n",
    "test_accuracy = np.mean(np.argmax(test_pred, axis=1) == np.argmax(mnist.y_test, axis=1))\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7995978",
   "metadata": {},
   "source": [
    "Once the MLP is trained, its weights and biases are stored in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c361e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'w1.npy'), np.array(mlp.weights['W1']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'w2.npy'), np.array(mlp.weights['W2']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'w3.npy'), np.array(mlp.weights['W3']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'w_out.npy'), np.array(mlp.weights['W4']))\n",
    "\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'b1.npy'), np.array(mlp.biases['b1']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'b2.npy'), np.array(mlp.biases['b2']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'b3.npy'), np.array(mlp.biases['b3']))\n",
    "np.save(os.path.join(config.WEIGHTS_AND_BIASES_PATH + r'\\mlp_0\\npy', 'b_out.npy'), np.array(mlp.biases['b4']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ring_oscillator_puf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
